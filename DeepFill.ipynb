{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.10 64-bit ('pytorch-env': conda)"
    },
    "interpreter": {
      "hash": "dc60f787052f1480302b36cd173f96b3b29cb481245b28980ba4e2a6880e8466"
    },
    "colab": {
      "name": "DeepFill.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agg-shambhavi/DeepFill/blob/master/DeepFill.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lJm0dMUivdK"
      },
      "source": [
        "# DeepFill"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG8IZ0qglLUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc00f512-4aad-4dfd-ad36-42c14af17102"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vto87QdNofYZ",
        "outputId": "8a2f075a-942e-4aec-dffc-92c92298914a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQBo26GDivdP"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw5UKljGivdQ"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.nn.init as init \n",
        "from torch.nn import Parameter\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5daGb1rntCA"
      },
      "source": [
        "## Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf3tcqvsnsrk"
      },
      "source": [
        "def extract_zip_file(path):\n",
        "  # extract all contents of zip file\n",
        "  zip_train = zipfile.ZipFile(path, 'r')\n",
        "  zip_train.extractall(\"./\")\n",
        "  zip_train.close()\n",
        "\n",
        "placesZip = \"/content/drive/MyDrive/Computer Vision /Inpainting/data256x256.zip\"\n",
        "\n",
        "extract_zip_file(placesZip)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tky1c8jivdR"
      },
      "source": [
        "## Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsKY1UNuivdS"
      },
      "source": [
        "class CelebA(Dataset):\n",
        "    def __init__(self, rootDir):\n",
        "        self.rootDir = rootDir\n",
        "        self.images = []\n",
        "        for filename in os.listdir(self.rootDir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                self.images.append(filename)\n",
        "\n",
        "        self.images_len = len(self.images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # load image\n",
        "        img = self.images[index % self.images_len]\n",
        "        img_path = os.path.join(self.rootDir, img)\n",
        "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (256, 256))\n",
        "\n",
        "        # load mask\n",
        "        mask = self.random_ff_mask(256)\n",
        "\n",
        "        # convert to torch\n",
        "        img = (\n",
        "            torch.from_numpy(img.astype(np.float32) / 255.0)\n",
        "            .permute(2, 0, 1)\n",
        "            .contiguous()\n",
        "        )\n",
        "        mask = torch.unsqueeze(torch.from_numpy(mask.astype(np.float32)).contiguous(), dim = 0)\n",
        "\n",
        "        return (img, mask)\n",
        "\n",
        "    def random_ff_mask(\n",
        "        self, mask_size, max_vertex=30, max_length=40, max_angle=4, max_brush_width=10\n",
        "    ):\n",
        "        mask = np.zeros((mask_size, mask_size), np.float32)\n",
        "        numVertex = np.random.randint(max_vertex)\n",
        "        for i in range(numVertex):\n",
        "            start_x = np.random.randint(mask_size)\n",
        "            start_y = np.random.randint(mask_size)\n",
        "            for j in range(1 + np.random.randint(5)):\n",
        "                angle = 0.01 + np.random.randint(max_angle)\n",
        "                if i % 2 == 0:\n",
        "                    angle = 2 * 3.141 - angle\n",
        "                length = 10 + np.random.randint(max_length)\n",
        "                brush_width = 5 + np.random.randint(max_brush_width)\n",
        "                end_x = (start_x + length * np.sin(angle)).astype(np.int32)\n",
        "                end_y = (start_y + length * np.cos(angle)).astype(np.int32)\n",
        "                cv2.line(mask, (start_x, start_y), (end_x, end_y), 1.0, brush_width)\n",
        "                start_x, start_y = end_x, end_y\n",
        "        return mask"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeAO8qRVivdS"
      },
      "source": [
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lto22R9BivdT"
      },
      "source": [
        "## implemnentation  taken of spectral norm from\n",
        "## https://github.com/avalonstrel/GatedConvolution_pytorch/blob/master/models/spectral.py\n",
        "\n",
        "def l2normalize(v, eps=1e-12):\n",
        "    return v / (v.norm() + eps)\n",
        "\n",
        "\n",
        "class SpectralNorm(nn.Module):\n",
        "    def __init__(self, module, name=\"weight\", power_iterations=1):\n",
        "        super(SpectralNorm, self).__init__()\n",
        "        self.module = module\n",
        "        self.name = name\n",
        "        self.power_iterations = power_iterations\n",
        "        if not self._made_params():\n",
        "            self._make_params()\n",
        "\n",
        "    def _update_u_v(self):\n",
        "        u = getattr(self.module, self.name + \"_u\")\n",
        "        v = getattr(self.module, self.name + \"_v\")\n",
        "        w = getattr(self.module, self.name + \"_bar\")\n",
        "\n",
        "        height = w.data.shape[0]\n",
        "        for _ in range(self.power_iterations):\n",
        "            v.data = l2normalize(torch.mv(torch.t(w.view(height, -1).data), u.data))\n",
        "            u.data = l2normalize(torch.mv(w.view(height, -1).data, v.data))\n",
        "\n",
        "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
        "        sigma = u.dot(w.view(height, -1).mv(v))\n",
        "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
        "\n",
        "    def _made_params(self):\n",
        "        try:\n",
        "            u = getattr(self.module, self.name + \"_u\")\n",
        "            v = getattr(self.module, self.name + \"_v\")\n",
        "            w = getattr(self.module, self.name + \"_bar\")\n",
        "            return True\n",
        "        except AttributeError:\n",
        "            return False\n",
        "\n",
        "    def _make_params(self):\n",
        "        w = getattr(self.module, self.name)\n",
        "\n",
        "        height = w.data.shape[0]\n",
        "        width = w.view(height, -1).data.shape[1]\n",
        "\n",
        "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
        "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
        "        u.data = l2normalize(u.data)\n",
        "        v.data = l2normalize(v.data)\n",
        "        w_bar = Parameter(w.data)\n",
        "\n",
        "        del self.module._parameters[self.name]\n",
        "\n",
        "        self.module.register_parameter(self.name + \"_u\", u)\n",
        "        self.module.register_parameter(self.name + \"_v\", v)\n",
        "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
        "\n",
        "    def forward(self, *args):\n",
        "        self._update_u_v()\n",
        "        return self.module.forward(*args)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk7Sz165ivdU"
      },
      "source": [
        "# Normal ConvBlock\n",
        "class Conv2dLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride=1,\n",
        "        padding=0,\n",
        "        dilation=1,\n",
        "        pad_type=\"zero\",\n",
        "        activation=\"elu\",\n",
        "        norm=\"none\",\n",
        "        sn=\"False\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        #  Initialize the padiing scheme\n",
        "        if pad_type == \"reflect\":\n",
        "            self.pad = nn.ReflectionPad2d(padding)\n",
        "        elif pad_type == \"replicate\":\n",
        "            self.pad = nn.ReplicationPad2d(padding)\n",
        "        elif pad_type == \"zero\":\n",
        "            self.pad = nn.ZeroPad2d(padding)\n",
        "        else:\n",
        "            assert 0, \"Unsupported padding type: {}\".format(pad_type)\n",
        "\n",
        "        # Initialize the normalization type\n",
        "        if norm == \"bn\":\n",
        "            self.norm = nn.BatchNorm2d(out_channels)\n",
        "        elif norm == \"in\":\n",
        "            self.norm = nn.InstanceNorm2d(out_channels)\n",
        "        # skipping layer norm here, becuase i dont we are using it anywhere\n",
        "        elif norm == \"none\":\n",
        "            self.norm = None\n",
        "        else:\n",
        "            assert 0, \"Unsupported normalization: {}\".format(norm)\n",
        "\n",
        "        # Initialize the activation function\n",
        "        if activation == \"relu\":\n",
        "            self.activation = nn.ReLU(inplace=True)\n",
        "        elif activation == \"lrelu\":\n",
        "            self.activation = nn.LeakyReLU(0.2, inplace=True)\n",
        "        elif activation == \"prelu\":\n",
        "            self.activation = nn.PReLU()\n",
        "        elif activation == \"selu\":\n",
        "            self.activation = nn.SELU(inplace=True)\n",
        "        elif activation == \"tanh\":\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == \"sigmoid\":\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif activation == \"none\":\n",
        "            self.activation = None\n",
        "        else:\n",
        "            assert 0, \"Unsupported activation: {}\".format(activation)\n",
        "\n",
        "        # Initialize the conv layer\n",
        "        if sn:\n",
        "            self.conv2d = SpectralNorm(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channels,\n",
        "                    out_channels=out_channels,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=stride,\n",
        "                    padding=padding,\n",
        "                    dilation=dilation,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            self.conv2d = nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=stride,\n",
        "                padding=padding,\n",
        "                dilation=dilation,\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pad(x)\n",
        "        x = self.conv2d(x)\n",
        "        if self.norm:\n",
        "            x = self.norm(x)\n",
        "        if self.activation:\n",
        "            x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOYg1KDvivdV"
      },
      "source": [
        "# Transpose ConvBlock\n",
        "class TransposeConv2dLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride=1,\n",
        "        padding=0,\n",
        "        dilation=1,\n",
        "        pad_type=\"zero\",\n",
        "        activation=\"lrelu\",\n",
        "        norm=\"none\",\n",
        "        sn=False,\n",
        "        scale_factor=2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "        self.conv2d = Conv2dLayer(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            stride,\n",
        "            padding,\n",
        "            dilation,\n",
        "            pad_type,\n",
        "            activation,\n",
        "            norm,\n",
        "            sn,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=\"nearest\")\n",
        "        return self.conv2d(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHLuIlHhivdW"
      },
      "source": [
        "# Gated ConvBlock\n",
        "class GatedConv2dLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride=1,\n",
        "        padding=0,\n",
        "        dilation=1,\n",
        "        pad_type=\"zero\",\n",
        "        activation=\"elu\",\n",
        "        norm=\"none\",\n",
        "        sn=\"False\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        #  Initialize the padiing scheme\n",
        "        if pad_type == \"reflect\":\n",
        "            self.pad = nn.ReflectionPad2d(padding)\n",
        "        elif pad_type == \"replicate\":\n",
        "            self.pad = nn.ReplicationPad2d(padding)\n",
        "        elif pad_type == \"zero\":\n",
        "            self.pad = nn.ZeroPad2d(padding)\n",
        "        else:\n",
        "            assert 0, \"Unsupported padding type: {}\".format(pad_type)\n",
        "\n",
        "        # Initialize the normalization type\n",
        "        if norm == \"bn\":\n",
        "            self.norm = nn.BatchNorm2d(out_channels)\n",
        "        elif norm == \"in\":\n",
        "            self.norm = nn.InstanceNorm2d(out_channels)\n",
        "        # skipping layer norm here, becuase i dont we are using it anywhere\n",
        "        elif norm == \"none\":\n",
        "            self.norm = None\n",
        "        else:\n",
        "            assert 0, \"Unsupported normalization: {}\".format(norm)\n",
        "\n",
        "        # Initialize the activation function\n",
        "        if activation == \"relu\":\n",
        "            self.activation = nn.ReLU(inplace=True)\n",
        "        elif activation == \"lrelu\":\n",
        "            self.activation = nn.LeakyReLU(0.2, inplace=True)\n",
        "        elif activation == \"prelu\":\n",
        "            self.activation = nn.PReLU()\n",
        "        elif activation == \"selu\":\n",
        "            self.activation = nn.SELU(inplace=True)\n",
        "        elif activation == \"tanh\":\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == \"sigmoid\":\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif activation == \"none\":\n",
        "            self.activation = None\n",
        "        else:\n",
        "            assert 0, \"Unsupported activation: {}\".format(activation)\n",
        "\n",
        "        # Initialize the conv layer\n",
        "        if sn:\n",
        "            self.conv2d = SpectralNorm(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channels,\n",
        "                    out_channels=out_channels,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=stride,\n",
        "                    padding=padding,\n",
        "                    dilation=dilation,\n",
        "                )\n",
        "            )\n",
        "            self.mask_conv2d = SpectralNorm(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channels,\n",
        "                    out_channels=out_channels,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=stride,\n",
        "                    padding=padding,\n",
        "                    dilation=dilation,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            self.conv2d = nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=stride,\n",
        "                padding=padding,\n",
        "                dilation=dilation,\n",
        "            )\n",
        "            self.mask_conv2d = nn.Conv2d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=kernel_size,\n",
        "                stride=stride,\n",
        "                padding=padding,\n",
        "                dilation=dilation,\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pad(x)\n",
        "        conv = self.conv2d(x)\n",
        "        mask = self.mask_conv2d(x)\n",
        "        gated_mask = self.sigmoid(mask)\n",
        "        x = conv * gated_mask\n",
        "        if self.norm:\n",
        "            x = self.norm(x)\n",
        "        if self.activation:\n",
        "            x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMu6_DMAivdY"
      },
      "source": [
        "# Transpose GatedConvBlock\n",
        "class TransposeGatedConv2dLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride=1,\n",
        "        padding=0,\n",
        "        dilation=1,\n",
        "        pad_type=\"zero\",\n",
        "        activation=\"lrelu\",\n",
        "        norm=\"none\",\n",
        "        sn=False,\n",
        "        scale_factor=2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "        self.gated_conv2d = GatedConv2dLayer(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            stride,\n",
        "            padding,\n",
        "            dilation,\n",
        "            pad_type,\n",
        "            activation,\n",
        "            norm,\n",
        "            sn,\n",
        "            scale_factor=2,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=\"nearest\")\n",
        "        return self.gated_conv2d(x)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gF7nDgdivda"
      },
      "source": [
        "## Weight Initialization Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apP9_8eDivda"
      },
      "source": [
        "# Weight Initialization\n",
        "def weights_init(net, init_type=\"kaiming\", init_gain=0.02):\n",
        "    \"\"\"\n",
        "    Initialize network weights.\n",
        "    Parameters:\n",
        "    net (network)  -- network to be initialized\n",
        "    init_type (str) -- initialization method: normal, xavier & orthogonal\n",
        "    init_var (float) -- scaling factor\n",
        "    \"\"\"\n",
        "\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, \"weight\") and classname.find(\"Conv\") != -1:\n",
        "            if init_type == \"normal\":\n",
        "                init.normal_(m.weight.data, 0.0, init_gain)\n",
        "            elif init_type == \"xavier\":\n",
        "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "            elif init_type == \"kaiming\":\n",
        "                init.kaiming_normal_(m.weight.data, a=0, mode=\"fan_in\")\n",
        "            elif init_type == \"orthogonal\":\n",
        "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
        "            else:\n",
        "                raise NotImplementedError(\n",
        "                    f\"Initialization method {init_type} is not implemented\"\n",
        "                )\n",
        "        elif classname.find(\"BatchNorm2d\") != -1:\n",
        "            init.normal_(m.weight.data, 1.0, 0.02)\n",
        "            init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find(\"Linear\") != -1:\n",
        "            init.normal_(m.weight, 0, 0.01)\n",
        "            init.constant_(m.bias, 0)\n",
        "\n",
        "    # now apply the initialization function here\n",
        "    net.apply(init_func)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJRdj_1civdb"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJI7tWfaivdb"
      },
      "source": [
        "# Generator\n",
        "# input: masked image + mask\n",
        "# output: filled image\n",
        "class GatedGenerator(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels, latent_channels, out_channels, pad_type, activation, norm\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # latent channels = 64\n",
        "        # in_channels = 4\n",
        "        # pad_type = zero\n",
        "        # activation = leaky relu\n",
        "        # norm = instance norm\n",
        "        self.coarse = nn.Sequential(\n",
        "            # encode initial layers\n",
        "            GatedConv2dLayer(\n",
        "                in_channels,\n",
        "                latent_channels,\n",
        "                7,\n",
        "                1,\n",
        "                3,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=\"none\",\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels,\n",
        "                latent_channels * 2,\n",
        "                4,\n",
        "                2,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 2,\n",
        "                latent_channels * 4,\n",
        "                4,\n",
        "                3,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                4,\n",
        "                2,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            # Bottleneck layer\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                2,\n",
        "                dilation=2,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                4,\n",
        "                dilation=4,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                8,\n",
        "                dilation=8,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                16,\n",
        "                dilation=16,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            # decoder\n",
        "            TransposeConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 2,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 2,\n",
        "                latent_channels * 2,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            TransposeConv2dLayer(\n",
        "                latent_channels * 2,\n",
        "                latent_channels,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels,\n",
        "                out_channels,\n",
        "                7,\n",
        "                1,\n",
        "                3,\n",
        "                pad_type=pad_type,\n",
        "                activation=\"tanh\",\n",
        "                norm=norm,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        self.refinement = nn.Sequential(\n",
        "            # encoder\n",
        "            GatedConv2dLayer(\n",
        "                in_channels,\n",
        "                latent_channels,\n",
        "                7,\n",
        "                1,\n",
        "                3,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=\"none\",\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels,\n",
        "                latent_channels * 2,\n",
        "                4,\n",
        "                2,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 2,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                4,\n",
        "                2,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            # Bottleneck\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                2,\n",
        "                dilation=2,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                4,\n",
        "                dilation=4,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                8,\n",
        "                dilation=8,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                16,\n",
        "                dilation=16,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            # decoder\n",
        "            TransposeConv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 2,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels * 2,\n",
        "                latent_channels * 2,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            TransposeConv2dLayer(\n",
        "                latent_channels * 2,\n",
        "                latent_channels,\n",
        "                3,\n",
        "                1,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "            ),\n",
        "            GatedConv2dLayer(\n",
        "                latent_channels,\n",
        "                out_channels,\n",
        "                7,\n",
        "                1,\n",
        "                3,\n",
        "                pad_type=pad_type,\n",
        "                activation=\"tanh\",\n",
        "                norm=norm,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def forward(self, img, mask):\n",
        "        print(img.shape)\n",
        "        print(mask.shape)\n",
        "        first_masked_img = img * (1 - mask) + mask\n",
        "        coarse_input = torch.cat(\n",
        "            (first_masked_img, mask), 1\n",
        "        )  # shape: batch_size, 4, H, W\n",
        "        coarse_out = self.coarse(coarse_input)\n",
        "        # refinement network\n",
        "        refine_masked_img = img * (1 - mask) + coarse_out\n",
        "        refine_input = torch.cat(\n",
        "            (refine_masked_img, mask), 1\n",
        "        )  # shape: batch_size, 4, H, W\n",
        "        refine_out = self.refinement(refine_input)\n",
        "        return coarse_out, refine_out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKSunUvWivde"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFGtF5QUivde"
      },
      "source": [
        "# Discriminator\n",
        "# Input: generated image + mask or image + mask\n",
        "# output: patch of size 30 * 30\n",
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, in_channels, latent_channels, pad_type, activation, norm):\n",
        "        super().__init__()\n",
        "        # Down-sample the input\n",
        "        self.block1 = (\n",
        "            Conv2dLayer(\n",
        "                in_channels,\n",
        "                latent_channels,\n",
        "                7,\n",
        "                1,\n",
        "                3,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=\"none\",\n",
        "                sn=True,\n",
        "            ),\n",
        "        )\n",
        "        self.block2 = (\n",
        "            Conv2dLayer(\n",
        "                latent_channels,\n",
        "                latent_channels * 2,\n",
        "                4,\n",
        "                2,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "                sn=True,\n",
        "            ),\n",
        "        )\n",
        "        self.block3 = (\n",
        "            Conv2dLayer(\n",
        "                latent_channels * 2,\n",
        "                latent_channels * 4,\n",
        "                4,\n",
        "                2,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "                sn=True,\n",
        "            ),\n",
        "        )\n",
        "        self.block4 = (\n",
        "            Conv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                4,\n",
        "                2,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "                sn=True,\n",
        "            ),\n",
        "        )\n",
        "        self.block5 = (\n",
        "            Conv2dLayer(\n",
        "                latent_channels * 4,\n",
        "                latent_channels * 4,\n",
        "                4,\n",
        "                2,\n",
        "                1,\n",
        "                pad_type=pad_type,\n",
        "                activation=activation,\n",
        "                norm=norm,\n",
        "                sn=True,\n",
        "            ),\n",
        "        )\n",
        "        self.block6 = Conv2dLayer(\n",
        "            latent_channels * 4,\n",
        "            1,\n",
        "            4,\n",
        "            2,\n",
        "            1,\n",
        "            pad_type=pad_type,\n",
        "            activation=\"none\",\n",
        "            norm=\"none\",\n",
        "            sn=True,\n",
        "        )\n",
        "\n",
        "    def forward(self, img, mask):\n",
        "        # concat the image and the mask\n",
        "        x = torch.cat((img, mask), 1)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "        return x\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCRg-P10ivdg"
      },
      "source": [
        "## Perceptual Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iTm0cfUivdg"
      },
      "source": [
        "# Perceptual Network\n",
        "# VGG-16 conv4_3 features\n",
        "class PerceptualNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PerceptualNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, 1, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, 1, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(256, 512, 3, 1, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSR2Sf2Mivdh"
      },
      "source": [
        "## Train Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsPGu4aVivdh"
      },
      "source": [
        "# train function\n",
        "def trainFn(\n",
        "    gen,\n",
        "    disc,\n",
        "    perceptNet,\n",
        "    opt_g,\n",
        "    opt_d,\n",
        "    train_loader,\n",
        "    epoch,\n",
        "    L1Loss,\n",
        "    lambda_l1,\n",
        "    lambda_perceptual,\n",
        "    lambda_gan,\n",
        "):\n",
        "    # LOOP through the data loader\n",
        "    for batch_idx, (img, mask) in enumerate(train_loader):\n",
        "\n",
        "        # Load img and mask to cuda\n",
        "        img = img.to(DEVICE)\n",
        "        mask = mask.to(DEVICE)\n",
        "\n",
        "        # generate output from generator\n",
        "        coarse_out, refine_out = gen(img, mask)\n",
        "\n",
        "        # fill the image\n",
        "        coarse_final_img = img * (1 - mask) + coarse_out * mask\n",
        "        refine_final_img = img * (1 - mask) + coarse_out * mask\n",
        "\n",
        "        # Train discriminators\n",
        "        # fake\n",
        "        fake_img = disc(refine_final_img.detch(), mask)\n",
        "        real_img = disc(img.detch(), mask)\n",
        "\n",
        "        # loss for discriminator and backprop and update\n",
        "        loss_D = torch.mean(fake_img) - torch.mean(real_img)\n",
        "        opt_d.zero_grad()\n",
        "        loss_D.backward()\n",
        "        opt_d.step()\n",
        "\n",
        "        # gen loss\n",
        "\n",
        "        # L1 Loss\n",
        "        coarse_L1Loss = L1Loss(coarse_final_img, img)\n",
        "        refine_L1Loss = L1Loss(refine_final_img, img)\n",
        "\n",
        "        # gan loss (wgan loss)\n",
        "        fake_img = disc(refine_final_img.detch(), mask)\n",
        "        gan_loss = -torch.mean(fake_img)\n",
        "\n",
        "        # perceptual loss\n",
        "        real_featureMaps = perceptNet(img)\n",
        "        fake_featureMaps = perceptNet(refine_final_img)\n",
        "        percept_loss = L1Loss(real_featureMaps, fake_featureMaps)\n",
        "\n",
        "        # grand total loss, backprop and update\n",
        "        loss_G = (\n",
        "            lambda_l1 * coarse_L1Loss\n",
        "            + lambda_l1 * refine_L1Loss\n",
        "            + lambda_perceptual * percept_loss\n",
        "            + lambda_gan * gan_loss\n",
        "        )\n",
        "        opt_g.zero_grad()\n",
        "        loss_G.backward()\n",
        "        opt_g.step()\n",
        "\n",
        "        # TODO: PRINT LOGS HERE"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QSwBhR5ivdi"
      },
      "source": [
        "## Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRQ7yI33ivdi"
      },
      "source": [
        "# main function\n",
        "def main():\n",
        "\n",
        "    # All constants\n",
        "\n",
        "    # Device\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # CONSTANTS for generator\n",
        "    IN_CHANNELS = 3\n",
        "    LATENT_CHANNELS = 64\n",
        "    OUT_CHANNELS = 3\n",
        "    PAD_TYPE = \"zero\"\n",
        "    NORM = \"in\"\n",
        "    ACTIVATION = \"lrelu\"\n",
        "\n",
        "    # Learning rate constants\n",
        "    LR_G = 1e-4\n",
        "    LR_D = 4e-4\n",
        "    BETA1 = 0.5\n",
        "    BETA2 = 0.999\n",
        "    lr_decrease_factor = 0.5\n",
        "    lr_decrease_epoch = 10\n",
        "\n",
        "    # All necessary paths\n",
        "    ROOTDIR_PATH = r\"/content/data256x256\"\n",
        "\n",
        "    # Training constants\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_EPOCHS = 1\n",
        "\n",
        "    # Loss Constants\n",
        "    lambda_l1 = 100\n",
        "    lambda_perceptual = 10\n",
        "    lambda_gan = 1\n",
        "\n",
        "    # Instantiate all networks\n",
        "\n",
        "    #  CREATE GENERATOR -> make gen object and initialize weights\n",
        "    gen = GatedGenerator(\n",
        "        in_channels=IN_CHANNELS,\n",
        "        latent_channels=LATENT_CHANNELS,\n",
        "        out_channels=OUT_CHANNELS,\n",
        "        pad_type=PAD_TYPE,\n",
        "        activation=ACTIVATION,\n",
        "        norm=NORM,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    weights_init(net=gen)\n",
        "\n",
        "    #  CREATE DISCRIMINATOR -> make disc object and initialize weights\n",
        "    disc = PatchDiscriminator(\n",
        "        in_channels=IN_CHANNELS,\n",
        "        latent_channels=LATENT_CHANNELS,\n",
        "        pad_type=PAD_TYPE,\n",
        "        activation=ACTIVATION,\n",
        "        norm=NORM,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    weights_init(net=disc)\n",
        "\n",
        "    # Instantiate Perceptual net\n",
        "\n",
        "    def load_dict(process_net, pretrained_net):\n",
        "        \"\"\"\n",
        "        Function to load pretrained network's state dict to our current network\n",
        "        \"\"\"\n",
        "        # Get the dict from pretrained net\n",
        "        # idk if state_dict()will be there or not\n",
        "        pretrained_dict = pretrained_net\n",
        "        # Get the dict from process_net\n",
        "        process_dict = process_net.state_dict()\n",
        "        # Delete the extra keys from pretrained_dict that do not belong to process_dict\n",
        "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in process_dict}\n",
        "        # Update process dict using pretrained_dict\n",
        "        process_dict.update(pretrained_dict)\n",
        "        # Load the updated dict to processing network\n",
        "        process_net.load_state_dict(process_dict)\n",
        "        return process_net\n",
        "\n",
        "    perceptNet = PerceptualNet().to(DEVICE)\n",
        "    vgg16 = torch.load(\"/content/drive/MyDrive/Computer Vision /Inpainting/vgg16_pretrained.pth\")\n",
        "    load_dict(perceptNet, vgg16)\n",
        "    for param in perceptNet.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Optimizers\n",
        "    opt_g = torch.optim.Adam(gen.parameters(), lr=LR_G, betas=(BETA1, BETA2))\n",
        "    opt_d = torch.optim.Adam(disc.parameters(), lr=LR_D, betas=(BETA1, BETA2))\n",
        "\n",
        "    # Loss functions\n",
        "    L1Loss = nn.L1Loss()\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    def adjust_lr(lr_in, optimizer, epoch, decrease_factor, lr_decrease_epoch):\n",
        "        \"\"\"\n",
        "        Set the lr to (decreased_factor * lr) to every lr_decrease_epoch\n",
        "        \"\"\"\n",
        "        lr = lr_in * (decrease_factor ** (epoch // lr_decrease_epoch))\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group[\"lr\"] = lr\n",
        "\n",
        "    # Initialize training data\n",
        "    train_dataset = CelebA(ROOTDIR_PATH)\n",
        "    train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(f\"Epoch {epoch}\")\n",
        "        trainFn(\n",
        "            gen,\n",
        "            disc,\n",
        "            perceptNet,\n",
        "            opt_g,\n",
        "            opt_d,\n",
        "            train_loader,\n",
        "            epoch,\n",
        "            L1Loss,\n",
        "            lambda_l1,\n",
        "            lambda_perceptual,\n",
        "            lambda_gan,\n",
        "        )\n",
        "        # Decrease learning rate\n",
        "        adjust_lr(LR_G, opt_g, epoch + 1, lr_decrease_factor, lr_decrease_epoch)\n",
        "        adjust_lr(LR_D, opt_d, epoch + 1, lr_decrease_factor, lr_decrease_epoch)\n",
        "\n",
        "        # TODO: FUNCTION TO SAVE MODEL\n",
        "\n",
        "        # TODO: SAMPLE IMAGES TO SAVE IN A FOLDER\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ozHzRbImpSUN",
        "outputId": "7eb288f5-5161-44be-eed8-fe385198297b"
      },
      "source": [
        "main()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "torch.Size([32, 3, 256, 256])\n",
            "torch.Size([32, 1, 256, 256])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-500873bbab00>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mlambda_l1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mlambda_perceptual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mlambda_gan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         )\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Decrease learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-455100253e0d>\u001b[0m in \u001b[0;36mtrainFn\u001b[0;34m(gen, disc, perceptNet, opt_g, opt_d, train_loader, epoch, L1Loss, lambda_l1, lambda_perceptual, lambda_gan)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# generate output from generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mcoarse_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefine_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# fill the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-82b078bb7f9d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, mask)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mfirst_masked_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         )  # shape: batch_size, 4, H, W\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mcoarse_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoarse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoarse_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0;31m# refinement network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mrefine_masked_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcoarse_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-cdb37367a0bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_conv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mgated_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d11c378a2e50>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_u_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[32, 4, 262, 262] to have 3 channels, but got 4 channels instead"
          ]
        }
      ]
    }
  ]
}