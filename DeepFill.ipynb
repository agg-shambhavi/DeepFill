{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DeepFill"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "import cv2\r\n",
    "import torch.nn as nn\r\n",
    "from torch.nn import functional as F\r\n",
    "import torch.nn.init as init \r\n",
    "from torch.nn import Parameter\r\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class CelebA(Dataset):\r\n",
    "    def __init__(self, rootDir):\r\n",
    "        self.rootDir = rootDir\r\n",
    "        self.images = []\r\n",
    "        for filename in os.listdir(self.rootDir):\r\n",
    "            if filename.endswith(\".jpg\"):\r\n",
    "                self.images.append(filename)\r\n",
    "\r\n",
    "        self.images_len = len(self.images)\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return self.images_len\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        # load image\r\n",
    "        img = self.images[index % self.images_len]\r\n",
    "        img_path = os.path.join(self.rootDir, img)\r\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\r\n",
    "        img = cv2.resize(img, (256, 256))\r\n",
    "\r\n",
    "        # load mask\r\n",
    "        mask = self.random_ff_mask(256)\r\n",
    "\r\n",
    "        # convert to torch\r\n",
    "        img = (\r\n",
    "            torch.from_numpy(img.astype(np.float32) / 255.0)\r\n",
    "            .permute(2, 0, 1)\r\n",
    "            .contiguous()\r\n",
    "        )\r\n",
    "        mask = torch.from_numpy(mask.astype(np.float32)).contiguous()\r\n",
    "\r\n",
    "        return (img, mask)\r\n",
    "\r\n",
    "    def random_ff_mask(\r\n",
    "        self, mask_size, max_vertex=30, max_length=40, max_angle=4, max_brush_width=10\r\n",
    "    ):\r\n",
    "        mask = np.zeros((mask_size, mask_size), np.float32)\r\n",
    "        numVertex = np.random.randint(max_vertex)\r\n",
    "        for i in range(numVertex):\r\n",
    "            start_x = np.random.randint(mask_size)\r\n",
    "            start_y = np.random.randint(mask_size)\r\n",
    "            for j in range(1 + np.random.randint(5)):\r\n",
    "                angle = 0.01 + np.random.randint(max_angle)\r\n",
    "                if i % 2 == 0:\r\n",
    "                    angle = 2 * 3.141 - angle\r\n",
    "                length = 10 + np.random.randint(max_length)\r\n",
    "                brush_width = 5 + np.random.randint(max_brush_width)\r\n",
    "                end_x = (start_x + length * np.sin(angle)).astype(np.int32)\r\n",
    "                end_y = (start_y + length * np.cos(angle)).astype(np.int32)\r\n",
    "                cv2.line(mask, (start_x, start_y), (end_x, end_y), 1.0, brush_width)\r\n",
    "                start_x, start_y = end_x, end_y\r\n",
    "        return mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## implemnentation  taken of spectral norm from\r\n",
    "## https://github.com/avalonstrel/GatedConvolution_pytorch/blob/master/models/spectral.py\r\n",
    "\r\n",
    "def l2normalize(v, eps=1e-12):\r\n",
    "    return v / (v.norm() + eps)\r\n",
    "\r\n",
    "\r\n",
    "class SpectralNorm(nn.Module):\r\n",
    "    def __init__(self, module, name=\"weight\", power_iterations=1):\r\n",
    "        super(SpectralNorm, self).__init__()\r\n",
    "        self.module = module\r\n",
    "        self.name = name\r\n",
    "        self.power_iterations = power_iterations\r\n",
    "        if not self._made_params():\r\n",
    "            self._make_params()\r\n",
    "\r\n",
    "    def _update_u_v(self):\r\n",
    "        u = getattr(self.module, self.name + \"_u\")\r\n",
    "        v = getattr(self.module, self.name + \"_v\")\r\n",
    "        w = getattr(self.module, self.name + \"_bar\")\r\n",
    "\r\n",
    "        height = w.data.shape[0]\r\n",
    "        for _ in range(self.power_iterations):\r\n",
    "            v.data = l2normalize(torch.mv(torch.t(w.view(height, -1).data), u.data))\r\n",
    "            u.data = l2normalize(torch.mv(w.view(height, -1).data, v.data))\r\n",
    "\r\n",
    "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\r\n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\r\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\r\n",
    "\r\n",
    "    def _made_params(self):\r\n",
    "        try:\r\n",
    "            u = getattr(self.module, self.name + \"_u\")\r\n",
    "            v = getattr(self.module, self.name + \"_v\")\r\n",
    "            w = getattr(self.module, self.name + \"_bar\")\r\n",
    "            return True\r\n",
    "        except AttributeError:\r\n",
    "            return False\r\n",
    "\r\n",
    "    def _make_params(self):\r\n",
    "        w = getattr(self.module, self.name)\r\n",
    "\r\n",
    "        height = w.data.shape[0]\r\n",
    "        width = w.view(height, -1).data.shape[1]\r\n",
    "\r\n",
    "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\r\n",
    "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\r\n",
    "        u.data = l2normalize(u.data)\r\n",
    "        v.data = l2normalize(v.data)\r\n",
    "        w_bar = Parameter(w.data)\r\n",
    "\r\n",
    "        del self.module._parameters[self.name]\r\n",
    "\r\n",
    "        self.module.register_parameter(self.name + \"_u\", u)\r\n",
    "        self.module.register_parameter(self.name + \"_v\", v)\r\n",
    "        self.module.register_parameter(self.name + \"_bar\", w_bar)\r\n",
    "\r\n",
    "    def forward(self, *args):\r\n",
    "        self._update_u_v()\r\n",
    "        return self.module.forward(*args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Normal ConvBlock\r\n",
    "class Conv2dLayer(nn.Module):\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        in_channels,\r\n",
    "        out_channels,\r\n",
    "        kernel_size,\r\n",
    "        stride=1,\r\n",
    "        padding=0,\r\n",
    "        dilation=1,\r\n",
    "        pad_type=\"zero\",\r\n",
    "        activation=\"elu\",\r\n",
    "        norm=\"none\",\r\n",
    "        sn=\"False\",\r\n",
    "    ):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        #  Initialize the padiing scheme\r\n",
    "        if pad_type == \"reflect\":\r\n",
    "            self.pad = nn.ReflectionPad2d(padding)\r\n",
    "        elif pad_type == \"replicate\":\r\n",
    "            self.pad = nn.ReplicationPad2d(padding)\r\n",
    "        elif pad_type == \"zero\":\r\n",
    "            self.pad = nn.ZeroPad2d(padding)\r\n",
    "        else:\r\n",
    "            assert 0, \"Unsupported padding type: {}\".format(pad_type)\r\n",
    "\r\n",
    "        # Initialize the normalization type\r\n",
    "        if norm == \"bn\":\r\n",
    "            self.norm = nn.BatchNorm2d(out_channels)\r\n",
    "        elif self.norm == \"in\":\r\n",
    "            self.norm = nn.InstanceNorm2d(out_channels)\r\n",
    "        # skipping layer norm here, becuase i dont we are using it anywhere\r\n",
    "        elif norm == \"none\":\r\n",
    "            self.norm = None\r\n",
    "        else:\r\n",
    "            assert 0, \"Unsupported normalization: {}\".format(norm)\r\n",
    "\r\n",
    "        # Initialize the activation function\r\n",
    "        if activation == \"relu\":\r\n",
    "            self.activation = nn.ReLU(inplace=True)\r\n",
    "        elif activation == \"lrelu\":\r\n",
    "            self.activation = nn.LeakyReLU(0.2, inplace=True)\r\n",
    "        elif activation == \"prelu\":\r\n",
    "            self.activation = nn.PReLU()\r\n",
    "        elif activation == \"selu\":\r\n",
    "            self.activation = nn.SELU(inplace=True)\r\n",
    "        elif activation == \"tanh\":\r\n",
    "            self.activation = nn.Tanh()\r\n",
    "        elif activation == \"sigmoid\":\r\n",
    "            self.activation = nn.Sigmoid()\r\n",
    "        elif activation == \"none\":\r\n",
    "            self.activation = None\r\n",
    "        else:\r\n",
    "            assert 0, \"Unsupported activation: {}\".format(activation)\r\n",
    "\r\n",
    "        # Initialize the conv layer\r\n",
    "        if sn:\r\n",
    "            self.conv2d = SpectralNorm(\r\n",
    "                nn.Conv2d(\r\n",
    "                    in_channels=in_channels,\r\n",
    "                    out_channels=out_channels,\r\n",
    "                    kernel_size=kernel_size,\r\n",
    "                    stride=stride,\r\n",
    "                    padding=padding,\r\n",
    "                    dilation=dilation,\r\n",
    "                )\r\n",
    "            )\r\n",
    "        else:\r\n",
    "            self.conv2d = nn.Conv2d(\r\n",
    "                in_channels=in_channels,\r\n",
    "                out_channels=out_channels,\r\n",
    "                kernel_size=kernel_size,\r\n",
    "                stride=stride,\r\n",
    "                padding=padding,\r\n",
    "                dilation=dilation,\r\n",
    "            )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.pad(x)\r\n",
    "        x = self.conv2d(x)\r\n",
    "        if self.norm:\r\n",
    "            x = self.norm(x)\r\n",
    "        if self.activation:\r\n",
    "            x = self.activation(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Transpose ConvBlock\r\n",
    "class TransposeConv2dLayer(nn.Module):\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        in_channels,\r\n",
    "        out_channels,\r\n",
    "        kernel_size,\r\n",
    "        stride=1,\r\n",
    "        padding=0,\r\n",
    "        dilation=1,\r\n",
    "        pad_type=\"zero\",\r\n",
    "        activation=\"lrelu\",\r\n",
    "        norm=\"none\",\r\n",
    "        sn=False,\r\n",
    "        scale_factor=2,\r\n",
    "    ):\r\n",
    "        super().__init__()\r\n",
    "        self.scale_factor = scale_factor\r\n",
    "        self.conv2d = Conv2dLayer(\r\n",
    "            in_channels,\r\n",
    "            out_channels,\r\n",
    "            kernel_size,\r\n",
    "            stride,\r\n",
    "            padding,\r\n",
    "            dilation,\r\n",
    "            pad_type,\r\n",
    "            activation,\r\n",
    "            norm,\r\n",
    "            sn,\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=\"nearest\")\r\n",
    "        return self.conv2d(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Gated ConvBlock\r\n",
    "class GatedConv2dLayer(nn.Module):\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        in_channels,\r\n",
    "        out_channels,\r\n",
    "        kernel_size,\r\n",
    "        stride=1,\r\n",
    "        padding=0,\r\n",
    "        dilation=1,\r\n",
    "        pad_type=\"zero\",\r\n",
    "        activation=\"elu\",\r\n",
    "        norm=\"none\",\r\n",
    "        sn=\"False\",\r\n",
    "    ):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        #  Initialize the padiing scheme\r\n",
    "        if pad_type == \"reflect\":\r\n",
    "            self.pad = nn.ReflectionPad2d(padding)\r\n",
    "        elif pad_type == \"replicate\":\r\n",
    "            self.pad = nn.ReplicationPad2d(padding)\r\n",
    "        elif pad_type == \"zero\":\r\n",
    "            self.pad = nn.ZeroPad2d(padding)\r\n",
    "        else:\r\n",
    "            assert 0, \"Unsupported padding type: {}\".format(pad_type)\r\n",
    "\r\n",
    "        # Initialize the normalization type\r\n",
    "        if norm == \"bn\":\r\n",
    "            self.norm = nn.BatchNorm2d(out_channels)\r\n",
    "        elif self.norm == \"in\":\r\n",
    "            self.norm = nn.InstanceNorm2d(out_channels)\r\n",
    "        # skipping layer norm here, becuase i dont we are using it anywhere\r\n",
    "        elif norm == \"none\":\r\n",
    "            self.norm = None\r\n",
    "        else:\r\n",
    "            assert 0, \"Unsupported normalization: {}\".format(norm)\r\n",
    "\r\n",
    "        # Initialize the activation function\r\n",
    "        if activation == \"relu\":\r\n",
    "            self.activation = nn.ReLU(inplace=True)\r\n",
    "        elif activation == \"lrelu\":\r\n",
    "            self.activation = nn.LeakyReLU(0.2, inplace=True)\r\n",
    "        elif activation == \"prelu\":\r\n",
    "            self.activation = nn.PReLU()\r\n",
    "        elif activation == \"selu\":\r\n",
    "            self.activation = nn.SELU(inplace=True)\r\n",
    "        elif activation == \"tanh\":\r\n",
    "            self.activation = nn.Tanh()\r\n",
    "        elif activation == \"sigmoid\":\r\n",
    "            self.activation = nn.Sigmoid()\r\n",
    "        elif activation == \"none\":\r\n",
    "            self.activation = None\r\n",
    "        else:\r\n",
    "            assert 0, \"Unsupported activation: {}\".format(activation)\r\n",
    "\r\n",
    "        # Initialize the conv layer\r\n",
    "        if sn:\r\n",
    "            self.conv2d = SpectralNorm(\r\n",
    "                nn.Conv2d(\r\n",
    "                    in_channels=in_channels,\r\n",
    "                    out_channels=out_channels,\r\n",
    "                    kernel_size=kernel_size,\r\n",
    "                    stride=stride,\r\n",
    "                    padding=padding,\r\n",
    "                    dilation=dilation,\r\n",
    "                )\r\n",
    "            )\r\n",
    "            self.mask_conv2d = SpectralNorm(\r\n",
    "                nn.Conv2d(\r\n",
    "                    in_channels=in_channels,\r\n",
    "                    out_channels=out_channels,\r\n",
    "                    kernel_size=kernel_size,\r\n",
    "                    stride=stride,\r\n",
    "                    padding=padding,\r\n",
    "                    dilation=dilation,\r\n",
    "                )\r\n",
    "            )\r\n",
    "        else:\r\n",
    "            self.conv2d = nn.Conv2d(\r\n",
    "                in_channels=in_channels,\r\n",
    "                out_channels=out_channels,\r\n",
    "                kernel_size=kernel_size,\r\n",
    "                stride=stride,\r\n",
    "                padding=padding,\r\n",
    "                dilation=dilation,\r\n",
    "            )\r\n",
    "            self.mask_conv2d = nn.Conv2d(\r\n",
    "                in_channels=in_channels,\r\n",
    "                out_channels=out_channels,\r\n",
    "                kernel_size=kernel_size,\r\n",
    "                stride=stride,\r\n",
    "                padding=padding,\r\n",
    "                dilation=dilation,\r\n",
    "            )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.pad(x)\r\n",
    "        conv = self.conv2d(x)\r\n",
    "        mask = self.mask_conv2d(x)\r\n",
    "        gated_mask = self.sigmoid(mask)\r\n",
    "        x = conv * gated_mask\r\n",
    "        if self.norm:\r\n",
    "            x = self.norm(x)\r\n",
    "        if self.activation:\r\n",
    "            x = self.activation(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Transpose GatedConvBlock\r\n",
    "class TransposeGatedConv2dLayer(nn.Module):\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        in_channels,\r\n",
    "        out_channels,\r\n",
    "        kernel_size,\r\n",
    "        stride=1,\r\n",
    "        padding=0,\r\n",
    "        dilation=1,\r\n",
    "        pad_type=\"zero\",\r\n",
    "        activation=\"lrelu\",\r\n",
    "        norm=\"none\",\r\n",
    "        sn=False,\r\n",
    "        scale_factor=2,\r\n",
    "    ):\r\n",
    "        super().__init__()\r\n",
    "        self.scale_factor = scale_factor\r\n",
    "        self.gated_conv2d = GatedConv2dLayer(\r\n",
    "            in_channels,\r\n",
    "            out_channels,\r\n",
    "            kernel_size,\r\n",
    "            stride,\r\n",
    "            padding,\r\n",
    "            dilation,\r\n",
    "            pad_type,\r\n",
    "            activation,\r\n",
    "            norm,\r\n",
    "            sn,\r\n",
    "            scale_factor=2,\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=\"nearest\")\r\n",
    "        return self.gated_conv2d(x)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Weight Initialization Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Weight Initialization\r\n",
    "def weights_init(net, init_type=\"kaiming\", init_gain=0.02):\r\n",
    "    \"\"\"\r\n",
    "    Initialize network weights.\r\n",
    "    Parameters:\r\n",
    "    net (network)  -- network to be initialized\r\n",
    "    init_type (str) -- initialization method: normal, xavier & orthogonal\r\n",
    "    init_var (float) -- scaling factor\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def init_func(m):\r\n",
    "        classname = m.__class__.__name__\r\n",
    "        print(classname)\r\n",
    "        if hasattr(m, \"weight\") and classname.find(\"Conv\") != -1:\r\n",
    "            if init_type == \"normal\":\r\n",
    "                init.normal_(m.weight.data, 0.0, init_gain)\r\n",
    "            elif init_type == \"xavier\":\r\n",
    "                init.xavier_normal_(m.weight.data, gain=init_gain)\r\n",
    "            elif init_type == \"kaiming\":\r\n",
    "                init.kaiming_normal_(m.weight.data, a=0, mode=\"fan_in\")\r\n",
    "            elif init_type == \"orthogonal\":\r\n",
    "                init.orthogonal_(m.weight.data, gain=init_gain)\r\n",
    "            else:\r\n",
    "                raise NotImplementedError(\r\n",
    "                    f\"Initialization method {init_type} is not implemented\"\r\n",
    "                )\r\n",
    "        elif classname.find(\"BatchNorm2d\") != -1:\r\n",
    "            init.normal_(m.weight.data, 1.0, 0.02)\r\n",
    "            init.constant_(m.bias.data, 0.0)\r\n",
    "        elif classname.find(\"Linear\") != -1:\r\n",
    "            init.normal_(m.weight, 0, 0.01)\r\n",
    "            init.constant_(m.bias, 0)\r\n",
    "\r\n",
    "    # now apply the initialization function here\r\n",
    "    net.apply(init_func)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generator\r\n",
    "# input: masked image + mask\r\n",
    "# output: filled image\r\n",
    "class GatedGenerator(nn.Module):\r\n",
    "    def __init__(\r\n",
    "        self, in_channels, latent_channels, out_channels, pad_type, activation, norm\r\n",
    "    ):\r\n",
    "        super().__init__()\r\n",
    "        # latent channels = 64\r\n",
    "        # in_channels = 4\r\n",
    "        # pad_type = zero\r\n",
    "        # activation = leaky relu\r\n",
    "        # norm = instance norm\r\n",
    "        self.coarse = nn.Sequential(\r\n",
    "            # encode initial layers\r\n",
    "            GatedConv2dLayer(\r\n",
    "                in_channels,\r\n",
    "                latent_channels,\r\n",
    "                7,\r\n",
    "                1,\r\n",
    "                3,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=\"none\",\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels,\r\n",
    "                latent_channels * 2,\r\n",
    "                4,\r\n",
    "                2,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 2,\r\n",
    "                latent_channels * 4,\r\n",
    "                4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                4,\r\n",
    "                2,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            # Bottleneck layer\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                2,\r\n",
    "                dilation=2,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                4,\r\n",
    "                dilation=4,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                8,\r\n",
    "                dilation=8,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                16,\r\n",
    "                dilation=16,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            # decoder\r\n",
    "            TransposeConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 2,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 2,\r\n",
    "                latent_channels * 2,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            TransposeConv2dLayer(\r\n",
    "                latent_channels * 2,\r\n",
    "                latent_channels,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels,\r\n",
    "                out_channels,\r\n",
    "                7,\r\n",
    "                1,\r\n",
    "                3,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=\"tanh\",\r\n",
    "                norm=\"norm\",\r\n",
    "            ),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.refinement = nn.Sequential(\r\n",
    "            # encoder\r\n",
    "            GatedConv2dLayer(\r\n",
    "                in_channels,\r\n",
    "                latent_channels,\r\n",
    "                7,\r\n",
    "                1,\r\n",
    "                3,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=\"none\",\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels,\r\n",
    "                latent_channels * 2,\r\n",
    "                4,\r\n",
    "                2,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 2,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                4,\r\n",
    "                2,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            # Bottleneck\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                2,\r\n",
    "                dilation=2,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                4,\r\n",
    "                dilation=4,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                8,\r\n",
    "                dilation=8,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                16,\r\n",
    "                dilation=16,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            # decoder\r\n",
    "            TransposeConv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 2,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels * 2,\r\n",
    "                latent_channels * 2,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            TransposeConv2dLayer(\r\n",
    "                latent_channels * 2,\r\n",
    "                latent_channels,\r\n",
    "                3,\r\n",
    "                1,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "            ),\r\n",
    "            GatedConv2dLayer(\r\n",
    "                latent_channels,\r\n",
    "                out_channels,\r\n",
    "                7,\r\n",
    "                1,\r\n",
    "                3,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=\"tanh\",\r\n",
    "                norm=\"norm\",\r\n",
    "            ),\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, img, mask):\r\n",
    "        first_masked_img = img * (1 - mask) + mask\r\n",
    "        coarse_input = torch.cat(\r\n",
    "            (first_masked_img, mask), 1\r\n",
    "        )  # shape: batch_size, 4, H, W\r\n",
    "        coarse_out = self.coarse(coarse_input)\r\n",
    "        # refinement network\r\n",
    "        refine_masked_img = img * (1 - mask) + coarse_out\r\n",
    "        refine_input = torch.cat(\r\n",
    "            (refine_masked_img, mask), 1\r\n",
    "        )  # shape: batch_size, 4, H, W\r\n",
    "        refine_out = self.refinement(refine_input)\r\n",
    "        return coarse_out, refine_out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discriminator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Discriminator\r\n",
    "# Input: generated image + mask or image + mask\r\n",
    "# output: patch of size 30 * 30\r\n",
    "class PatchDiscriminator(nn.Module):\r\n",
    "    def __init__(self, in_channels, latent_channels, pad_type, activation, norm):\r\n",
    "        super().__init__()\r\n",
    "        # Down-sample the input\r\n",
    "        self.block1 = (\r\n",
    "            Conv2dLayer(\r\n",
    "                in_channels,\r\n",
    "                latent_channels,\r\n",
    "                7,\r\n",
    "                1,\r\n",
    "                3,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=\"none\",\r\n",
    "                sn=True,\r\n",
    "            ),\r\n",
    "        )\r\n",
    "        self.block2 = (\r\n",
    "            Conv2dLayer(\r\n",
    "                latent_channels,\r\n",
    "                latent_channels * 2,\r\n",
    "                4,\r\n",
    "                2,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "                sn=True,\r\n",
    "            ),\r\n",
    "        )\r\n",
    "        self.block3 = (\r\n",
    "            Conv2dLayer(\r\n",
    "                latent_channels * 2,\r\n",
    "                latent_channels * 4,\r\n",
    "                4,\r\n",
    "                2,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "                sn=True,\r\n",
    "            ),\r\n",
    "        )\r\n",
    "        self.block4 = (\r\n",
    "            Conv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                4,\r\n",
    "                2,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "                sn=True,\r\n",
    "            ),\r\n",
    "        )\r\n",
    "        self.block5 = (\r\n",
    "            Conv2dLayer(\r\n",
    "                latent_channels * 4,\r\n",
    "                latent_channels * 4,\r\n",
    "                4,\r\n",
    "                2,\r\n",
    "                1,\r\n",
    "                pad_type=pad_type,\r\n",
    "                activation=activation,\r\n",
    "                norm=norm,\r\n",
    "                sn=True,\r\n",
    "            ),\r\n",
    "        )\r\n",
    "        self.block6 = Conv2dLayer(\r\n",
    "            latent_channels * 4,\r\n",
    "            1,\r\n",
    "            4,\r\n",
    "            2,\r\n",
    "            1,\r\n",
    "            pad_type=pad_type,\r\n",
    "            activation=\"none\",\r\n",
    "            norm=\"none\",\r\n",
    "            sn=True,\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, img, mask):\r\n",
    "        # concat the image and the mask\r\n",
    "        x = torch.cat((img, mask), 1)\r\n",
    "        x = self.block1(x)\r\n",
    "        x = self.block2(x)\r\n",
    "        x = self.block3(x)\r\n",
    "        x = self.block4(x)\r\n",
    "        x = self.block5(x)\r\n",
    "        x = self.block6(x)\r\n",
    "        return x\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perceptual Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Perceptual Network\r\n",
    "# VGG-16 conv4_3 features\r\n",
    "class PerceptualNet(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(PerceptualNet, self).__init__()\r\n",
    "        self.features = nn.Sequential(\r\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(64, 64, 3, 1, 1),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.MaxPool2d(2, 2),\r\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(128, 128, 3, 1, 1),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.MaxPool2d(2, 2),\r\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\r\n",
    "            nn.MaxPool2d(2, 2),\r\n",
    "            nn.Conv2d(256, 512, 3, 1, 1),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.features(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train function\r\n",
    "def trainFn(\r\n",
    "    gen,\r\n",
    "    disc,\r\n",
    "    perceptNet,\r\n",
    "    opt_g,\r\n",
    "    opt_d,\r\n",
    "    train_loader,\r\n",
    "    epoch,\r\n",
    "    L1Loss,\r\n",
    "    lambda_l1,\r\n",
    "    lambda_perceptual,\r\n",
    "    lambda_gan,\r\n",
    "):\r\n",
    "    # LOOP through the data loader\r\n",
    "    for batch_idx, (img, mask) in train_loader:\r\n",
    "\r\n",
    "        # Load img and mask to cuda\r\n",
    "        img = img.TO(DEVICE)\r\n",
    "        mask = mask.TO(DEVICE)\r\n",
    "\r\n",
    "        # generate output from generator\r\n",
    "        coarse_out, refine_out = gen(img, mask)\r\n",
    "\r\n",
    "        # fill the image\r\n",
    "        coarse_final_img = img * (1 - mask) + coarse_out * mask\r\n",
    "        refine_final_img = img * (1 - mask) + coarse_out * mask\r\n",
    "\r\n",
    "        # Train discriminators\r\n",
    "        # fake\r\n",
    "        fake_img = disc(refine_final_img.detch(), mask)\r\n",
    "        real_img = disc(img.detch(), mask)\r\n",
    "\r\n",
    "        # loss for discriminator and backprop and update\r\n",
    "        loss_D = torch.mean(fake_img) - torch.mean(real_img)\r\n",
    "        opt_d.zero_grad()\r\n",
    "        loss_D.backward()\r\n",
    "        opt_d.step()\r\n",
    "\r\n",
    "        # gen loss\r\n",
    "\r\n",
    "        # L1 Loss\r\n",
    "        coarse_L1Loss = L1Loss(coarse_final_img, img)\r\n",
    "        refine_L1Loss = L1Loss(refine_final_img, img)\r\n",
    "\r\n",
    "        # gan loss (wgan loss)\r\n",
    "        fake_img = disc(refine_final_img.detch(), mask)\r\n",
    "        gan_loss = -torch.mean(fake_img)\r\n",
    "\r\n",
    "        # perceptual loss\r\n",
    "        real_featureMaps = perceptNet(img)\r\n",
    "        fake_featureMaps = perceptNet(refine_final_img)\r\n",
    "        percept_loss = L1Loss(real_featureMaps, fake_featureMaps)\r\n",
    "\r\n",
    "        # grand total loss, backprop and update\r\n",
    "        loss_G = (\r\n",
    "            lambda_l1 * coarse_L1Loss\r\n",
    "            + lambda_l1 * refine_L1Loss\r\n",
    "            + lambda_perceptual * percept_loss\r\n",
    "            + lambda_gan * gan_loss\r\n",
    "        )\r\n",
    "        opt_g.zero_grad()\r\n",
    "        loss_G.backward()\r\n",
    "        opt_g.step()\r\n",
    "\r\n",
    "        # TODO: PRINT LOGS HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# main function\r\n",
    "def main():\r\n",
    "\r\n",
    "    # All constants\r\n",
    "\r\n",
    "    # Device\r\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "\r\n",
    "    # CONSTANTS for generator\r\n",
    "    IN_CHANNELS = 3\r\n",
    "    LATENT_CHANNELS = 64\r\n",
    "    OUT_CHANNELS = 3\r\n",
    "    PAD_TYPE = \"zero\"\r\n",
    "    NORM = \"in\"\r\n",
    "    ACTIVATION = \"lrelu\"\r\n",
    "\r\n",
    "    # Learning rate constants\r\n",
    "    LR_G = 1e-4\r\n",
    "    LR_D = 4e-4\r\n",
    "    BETA1 = 0.5\r\n",
    "    BETA2 = 0.999\r\n",
    "    lr_decrease_factor = 0.5\r\n",
    "    lr_decrease_epoch = 10\r\n",
    "\r\n",
    "    # All necessary paths\r\n",
    "    ROOTDIR_PATH = r\"G:\\DeepFill\\Data\\data256x256\"\r\n",
    "\r\n",
    "    # Training constants\r\n",
    "    BATCH_SIZE = 32\r\n",
    "    NUM_EPOCHS = 1\r\n",
    "\r\n",
    "    # Loss Constants\r\n",
    "    lambda_l1 = 100\r\n",
    "    lambda_perceptual = 10\r\n",
    "    lambda_gan = 1\r\n",
    "\r\n",
    "    # Instantiate all networks\r\n",
    "\r\n",
    "    #  CREATE GENERATOR -> make gen object and initialize weights\r\n",
    "    gen = GatedGenerator(\r\n",
    "        in_channels=IN_CHANNELS,\r\n",
    "        latent_channels=LATENT_CHANNELS,\r\n",
    "        out_channels=OUT_CHANNELS,\r\n",
    "        pad_type=PAD_TYPE,\r\n",
    "        activation=ACTIVATION,\r\n",
    "        norm=NORM,\r\n",
    "    ).to(DEVICE)\r\n",
    "\r\n",
    "    weights_init(net=gen)\r\n",
    "\r\n",
    "    #  CREATE DISCRIMINATOR -> make disc object and initialize weights\r\n",
    "    disc = PatchDiscriminator(\r\n",
    "        in_channels=IN_CHANNELS,\r\n",
    "        latent_channels=LATENT_CHANNELS,\r\n",
    "        pad_type=PAD_TYPE,\r\n",
    "        activation=ACTIVATION,\r\n",
    "        norm=NORM,\r\n",
    "    ).to(DEVICE)\r\n",
    "\r\n",
    "    weights_init(net=disc)\r\n",
    "\r\n",
    "    # Instantiate Perceptual net\r\n",
    "\r\n",
    "    def load_dict(process_net, pretrained_net):\r\n",
    "        \"\"\"\r\n",
    "        Function to load pretrained network's state dict to our current network\r\n",
    "        \"\"\"\r\n",
    "        # Get the dict from pretrained net\r\n",
    "        # idk if state_dict()will be there or not\r\n",
    "        pretrained_dict = pretrained_net.state_dict()\r\n",
    "        # Get the dict from process_net\r\n",
    "        process_dict = process_net.state_dict()\r\n",
    "        # Delete the extra keys from pretrained_dict that do not belong to process_dict\r\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict if k in process_dict}\r\n",
    "        # Update process dict using pretrained_dict\r\n",
    "        process_dict.update(pretrained_dict)\r\n",
    "        # Load the updated dict to processing network\r\n",
    "        process_net.load_state_dict(process_dict)\r\n",
    "        return process_net\r\n",
    "\r\n",
    "    perceptNet = PerceptualNet().to(DEVICE)\r\n",
    "    vgg16 = torch.load(\"./Data/vgg16_pretrained.pth\").to(DEVICE)\r\n",
    "    load_dict(perceptNet, vgg16)\r\n",
    "    for param in perceptNet.parameters():\r\n",
    "        param.requires_grad = False\r\n",
    "\r\n",
    "    # Optimizers\r\n",
    "    opt_g = torch.optim.Adam(gen.parameters(), lr=LR_G, betas=(BETA1, BETA2))\r\n",
    "    opt_d = torch.optim.Adam(disc.parameters(), lr=LR_D, betas=(BETA1, BETA2))\r\n",
    "\r\n",
    "    # Loss functions\r\n",
    "    L1Loss = nn.L1Loss()\r\n",
    "\r\n",
    "    # Learning rate scheduler\r\n",
    "    def adjust_lr(lr_in, optimizer, epoch, decrease_factor, lr_decrease_epoch):\r\n",
    "        \"\"\"\r\n",
    "        Set the lr to (decreased_factor * lr) to every lr_decrease_epoch\r\n",
    "        \"\"\"\r\n",
    "        lr = lr_in * (decrease_factor ** (epoch // lr_decrease_epoch))\r\n",
    "        for param_group in optimizer.param_groups:\r\n",
    "            param_group[\"lr\"] = lr\r\n",
    "\r\n",
    "    # Initialize training data\r\n",
    "    train_dataset = dataset.CelebA(ROOTDIR_PATH)\r\n",
    "    train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\r\n",
    "\r\n",
    "    # Training loop\r\n",
    "    for epoch in range(NUM_EPOCHS):\r\n",
    "        print(f\"Epoch {epoch}\")\r\n",
    "        trainFn(\r\n",
    "            gen,\r\n",
    "            disc,\r\n",
    "            perceptNet,\r\n",
    "            opt_g,\r\n",
    "            opt_d,\r\n",
    "            train_loader,\r\n",
    "            epoch,\r\n",
    "            L1Loss,\r\n",
    "            lambda_l1,\r\n",
    "            lambda_perceptual,\r\n",
    "            lambda_gan,\r\n",
    "        )\r\n",
    "        # Decrease learning rate\r\n",
    "        adjust_lr(LR_G, opt_g, epoch + 1, lr_decrease_factor, lr_decrease_epoch)\r\n",
    "        adjust_lr(LR_D, opt_d, epoch + 1, lr_decrease_factor, lr_decrease_epoch)\r\n",
    "\r\n",
    "        # TODO: FUNCTION TO SAVE MODEL\r\n",
    "\r\n",
    "        # TODO: SAMPLE IMAGES TO SAVE IN A FOLDER\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('pytorch-env': conda)"
  },
  "interpreter": {
   "hash": "dc60f787052f1480302b36cd173f96b3b29cb481245b28980ba4e2a6880e8466"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}